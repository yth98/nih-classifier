{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten, InputLayer, LeakyReLU, BatchNormalization, Dropout, GlobalAveragePooling2D\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from dataset_batch import load_train_data, load_test_data\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_keras_metric(method):\n",
    "    import functools\n",
    "    from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    @functools.wraps(method)\n",
    "    def wrapper(self, args, **kwargs):\n",
    "        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n",
    "        value, update_op = method(self, args, **kwargs)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([update_op]):\n",
    "            value = tf.identity(value)\n",
    "        return value\n",
    "    return wrapper\n",
    "\n",
    "class DenseNetModel():\n",
    "    \n",
    "    def __init__(self, input_dim=(224,224,3), output_dim=14, learning_rate=0.00001, epochs=5, drop_out=0.3):\n",
    "\n",
    "        # parms:\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.drop_out = drop_out\n",
    "    \n",
    "        # Define DenseNet\n",
    "        self.model = Sequential()\n",
    "\n",
    "        base_model = DenseNet121(weights='imagenet', include_top=False, pooling='avg', input_shape=self.input_dim)\n",
    "        \n",
    "        # Freeze the model first\n",
    "        base_model.trainable = False\n",
    "\n",
    "        self.model.add(base_model)\n",
    "\n",
    "        self.model.add(Dropout(self.drop_out))\n",
    "        self.model.add(Dense(512))\n",
    "        self.model.add(Dropout(self.drop_out))\n",
    "        self.model.add(Dense(self.output_dim, activation = 'sigmoid'))\n",
    "\n",
    "        auc_roc = as_keras_metric(tf.metrics.auc)\n",
    "        recall = as_keras_metric(tf.metrics.recall)\n",
    "        precision = as_keras_metric(tf.metrics.precision)\n",
    "\n",
    "        self.model.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n",
    "                           metrics = ['binary_accuracy', 'mae', auc_roc, recall, precision])\n",
    "        self.model.summary()\n",
    "\n",
    "        # Image augmentation\n",
    "        self.core_idg = ImageDataGenerator(samplewise_center=True, \n",
    "                              samplewise_std_normalization=True, \n",
    "                              horizontal_flip = True, \n",
    "                              vertical_flip = False, \n",
    "                              height_shift_range= 0.05, \n",
    "                              width_shift_range=0.1, \n",
    "                              rotation_range=5, \n",
    "                              shear_range = 0.1,\n",
    "                              fill_mode = 'reflect',\n",
    "                              zoom_range=0.15)\n",
    "\n",
    "    # Data standardization\n",
    "    def standardize(self, x):\n",
    "        self.core_idg.fit(x)\n",
    "        return\n",
    "        \n",
    "    def fit(self, x, y, vx, vy):\n",
    "\n",
    "        # fit the data\n",
    "        print (\"Start Training model\")\n",
    "        X_train, y_train, X_test, y_test = x, y, vx, vy\n",
    "        hist = self.model.fit_generator(\n",
    "            (self.core_idg.flow(X_train, y_train, batch_size = 32)),\n",
    "            validation_data = self.core_idg.flow(X_test, y_test), epochs=self.epochs)\n",
    "        \n",
    "        print (\"Done Training model\")\n",
    "        print (\"AVG AUC:\", self.score(X_test, y_test))\n",
    "        return hist\n",
    "    \n",
    "    # data did preprocessing            \n",
    "    def inference(self, x):\n",
    "        return self.model.predict(x)\n",
    "\n",
    "    def score(self, x, y):\n",
    "        \n",
    "        # make predicition\n",
    "        y_pred = self.predict(x)\n",
    "        auc_val = 0.0\n",
    "\n",
    "        # calculate score\n",
    "        for idx in range(self.output_dim):\n",
    "            fpr, tpr, _ = roc_curve(y[:,idx].astype(int), y_pred[:,idx])\n",
    "            auc_val += auc(fpr, tpr)\n",
    "        \n",
    "        return auc_val / self.output_dim\n",
    "\n",
    "    # pain data without preprocessing\n",
    "    def predict(self, x):\n",
    "        x = self.core_idg.standardize(x)\n",
    "        return self.inference(x)\n",
    "\n",
    "    def save_weight(self, path = 'baseline.h5'):\n",
    "        print (\"Start Saving model\")\n",
    "        self.model.save(path)\n",
    "        print (\"Done Saving model\")\n",
    "        return\n",
    "\n",
    "    def load_weight(self, path = 'baseline.h5'):\n",
    "        print (\"Start Loading model\")\n",
    "        self.model.load_weights(path)\n",
    "        print (\"Done Loading model\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet121 (Model)          (None, 1024)              7037504   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 14)                7182      \n",
      "=================================================================\n",
      "Total params: 7,569,486\n",
      "Trainable params: 531,982\n",
      "Non-trainable params: 7,037,504\n",
      "_________________________________________________________________\n",
      "Loading Training Images and Labels\n",
      "0.0 % done\n",
      "1.0 % done\n",
      "2.0 % done\n",
      "3.0 % done\n",
      "4.0 % done\n",
      "5.0 % done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsien/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3183: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0 % done\n",
      "7.0 % done\n",
      "8.0 % done\n",
      "9.0 % done\n",
      "10.0 % done\n",
      "11.0 % done\n",
      "12.0 % done\n",
      "13.0 % done\n",
      "14.0 % done\n",
      "15.0 % done\n",
      "16.0 % done\n",
      "17.0 % done\n",
      "18.0 % done\n",
      "19.0 % done\n",
      "20.0 % done\n",
      "21.0 % done\n",
      "22.0 % done\n",
      "23.0 % done\n",
      "24.0 % done\n",
      "25.0 % done\n",
      "26.0 % done\n",
      "27.0 % done\n",
      "28.0 % done\n",
      "29.0 % done\n",
      "30.0 % done\n",
      "31.0 % done\n",
      "32.0 % done\n",
      "33.0 % done\n",
      "34.0 % done\n",
      "35.0 % done\n",
      "36.0 % done\n",
      "37.0 % done\n",
      "38.0 % done\n",
      "39.0 % done\n",
      "40.0 % done\n",
      "41.0 % done\n",
      "42.0 % done\n",
      "43.0 % done\n",
      "44.0 % done\n",
      "45.0 % done\n",
      "46.0 % done\n",
      "47.0 % done\n",
      "48.0 % done\n",
      "49.0 % done\n",
      "50.0 % done\n",
      "51.0 % done\n",
      "52.0 % done\n",
      "53.0 % done\n",
      "54.0 % done\n",
      "55.0 % done\n",
      "56.0 % done\n",
      "57.0 % done\n",
      "58.0 % done\n",
      "59.0 % done\n",
      "60.0 % done\n",
      "61.0 % done\n",
      "62.0 % done\n",
      "63.0 % done\n",
      "64.0 % done\n",
      "65.0 % done\n",
      "66.0 % done\n",
      "67.0 % done\n",
      "68.0 % done\n",
      "69.0 % done\n",
      "70.0 % done\n",
      "71.0 % done\n",
      "72.0 % done\n",
      "73.0 % done\n",
      "74.0 % done\n",
      "75.0 % done\n",
      "76.0 % done\n",
      "77.0 % done\n",
      "78.0 % done\n",
      "79.0 % done\n",
      "80.0 % done\n",
      "81.0 % done\n",
      "82.0 % done\n",
      "83.0 % done\n",
      "84.0 % done\n",
      "85.0 % done\n",
      "86.0 % done\n",
      "87.0 % done\n",
      "88.0 % done\n",
      "89.0 % done\n",
      "90.0 % done\n",
      "91.0 % done\n",
      "92.0 % done\n",
      "93.0 % done\n",
      "94.0 % done\n",
      "95.0 % done\n",
      "96.0 % done\n",
      "97.0 % done\n",
      "98.0 % done\n",
      "99.0 % done\n",
      "100.0 % done\n",
      "Done Loading Training Images and Labels from 9500 to 10002\n",
      "(502, 224, 224, 3) (502, 14)\n",
      "Loading Training Images and Labels\n",
      "0.0 % done\n",
      "1.0 % done\n",
      "2.0 % done\n",
      "3.0 % done\n",
      "4.0 % done\n",
      "5.0 % done\n",
      "6.0 % done\n",
      "7.0 % done\n",
      "8.0 % done\n",
      "9.0 % done\n",
      "10.0 % done\n",
      "11.0 % done\n",
      "12.0 % done\n",
      "13.0 % done\n",
      "14.0 % done\n",
      "15.0 % done\n",
      "16.0 % done\n",
      "17.0 % done\n",
      "18.0 % done\n",
      "19.0 % done\n",
      "20.0 % done\n",
      "21.0 % done\n",
      "22.0 % done\n",
      "23.0 % done\n",
      "24.0 % done\n",
      "25.0 % done\n",
      "26.0 % done\n",
      "27.0 % done\n",
      "28.0 % done\n",
      "29.0 % done\n",
      "30.0 % done\n",
      "31.0 % done\n",
      "32.0 % done\n",
      "33.0 % done\n",
      "34.0 % done\n",
      "35.0 % done\n",
      "36.0 % done\n",
      "37.0 % done\n",
      "38.0 % done\n",
      "39.0 % done\n",
      "40.0 % done\n",
      "41.0 % done\n",
      "42.0 % done\n",
      "43.0 % done\n",
      "44.0 % done\n",
      "45.0 % done\n",
      "46.0 % done\n",
      "47.0 % done\n",
      "48.0 % done\n",
      "49.0 % done\n",
      "50.0 % done\n",
      "51.0 % done\n",
      "52.0 % done\n",
      "53.0 % done\n",
      "54.0 % done\n",
      "55.0 % done\n",
      "56.0 % done\n",
      "57.0 % done\n",
      "58.0 % done\n",
      "59.0 % done\n",
      "60.0 % done\n",
      "61.0 % done\n",
      "62.0 % done\n",
      "63.0 % done\n",
      "64.0 % done\n",
      "65.0 % done\n",
      "66.0 % done\n",
      "67.0 % done\n",
      "68.0 % done\n",
      "69.0 % done\n",
      "70.0 % done\n",
      "71.0 % done\n",
      "72.0 % done\n",
      "73.0 % done\n",
      "74.0 % done\n",
      "75.0 % done\n",
      "76.0 % done\n",
      "77.0 % done\n",
      "78.0 % done\n",
      "79.0 % done\n",
      "80.0 % done\n",
      "81.0 % done\n",
      "82.0 % done\n",
      "83.0 % done\n",
      "84.0 % done\n",
      "85.0 % done\n",
      "86.0 % done\n",
      "87.0 % done\n",
      "88.0 % done\n",
      "89.0 % done\n",
      "90.0 % done\n",
      "91.0 % done\n",
      "92.0 % done\n",
      "93.0 % done\n",
      "94.0 % done\n",
      "95.0 % done\n",
      "96.0 % done\n",
      "97.0 % done\n",
      "98.0 % done\n",
      "99.0 % done\n",
      "100.0 % done\n",
      "Done Loading Training Images and Labels from 0 to 499\n",
      "(500, 224, 224, 3) (500, 14)\n",
      "Start Training model\n",
      "Epoch 1/5\n",
      "16/16 [==============================] - 301s 19s/step - loss: 0.3188 - binary_accuracy: 0.9092 - mean_absolute_error: 0.1155 - auc: 0.5256 - recall: 0.9374 - precision: 0.0434 - val_loss: 0.3072 - val_binary_accuracy: 0.9535 - val_mean_absolute_error: 0.0592 - val_auc: 0.5938 - val_recall: 1.0000 - val_precision: 0.0480\n",
      "Epoch 2/5\n",
      " 4/16 [======>.......................] - ETA: 1:48 - loss: 0.2671 - binary_accuracy: 0.9308 - mean_absolute_error: 0.0972 - auc: 0.5945 - recall: 1.0000 - precision: 0.0481"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-aecf210343c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_cnt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_cnt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m499\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_vali\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_vali\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Saving model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-4a67c1262c77>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, vx, vy)\u001b[0m\n\u001b[1;32m     71\u001b[0m         hist = self.model.fit_generator(\n\u001b[1;32m     72\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore_idg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             validation_data = self.core_idg.flow(X_test, y_test), epochs=self.epochs)\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Done Training model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1313\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1883\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    model = DenseNetModel(input_dim=(224,224,3), epochs=5)\n",
    "\n",
    "    X_vali, y_vali = load_train_data(min_cnt=9500, max_cnt=10002)\n",
    "    for iter in range(10):\n",
    "        for base in range(0, 9500, 500):\n",
    "            X_train, y_train = load_train_data(min_cnt=base, max_cnt=base+499)\n",
    "            model.standardize(X_train)\n",
    "            model.fit(X_train, y_train, X_vali, y_vali)\n",
    "\n",
    "    # Saving model\n",
    "    model.save_weight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
